{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Report\n",
    "\n",
    "- What steps of the plan were performed and what steps were skipped (explain why)?\n",
    "- What difficulties did you encounter and how did you manage to solve them?\n",
    "- What were some of the key steps to solving the task?\n",
    "- What is your final model and what quality score does it have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following steps were performed:**\n",
    "\n",
    "  1) Exploratory analysis around gender, senior citizen and characteristics of the customers have revealed some useful insights into this question, and it uncovered some useful insights into the behaviour of churned customers.<br/>\n",
    "  \n",
    "  1.1) Some of them are the mean monthly spend for a churned customer is higher by $13 compared with an active customer.<br/>\n",
    "  \n",
    "  1.2) 1037(47%) of the customers who sign up in the first year churn.<br/>\n",
    "  \n",
    "  1.3) Other behaviour noted among the churned customers are: a) customers with no dependents or partners tend to easily churn. b) Monthly billing gives them an easy exit option. c) Paperless billing and Fiber optic internet plan have been a thorn in retaining such customers.<br/>\n",
    "  \n",
    "  2) The missing values in `TotalCharges` were imputed using SimpleImputer. Initially, I thought I would infer them based on the `MonthlyCharges`, but I noticed that the monthly charges even for the same duration and set of services differ slightly. Imputation didn't shift the median much. I also imputed the \"missing\" values for `MultipleLines` and various Internet services as I was under the assumption that they were missing at random. But, I was advised that this wasn't the case, so after merging the datasets, I filled them with a response of \"No\".\n",
    "  \n",
    "  2.1) I skipped the idea of imputing them using LogisticRegression as it would have been overkill for this problem.\n",
    "  \n",
    "  3) In the feature engineering step, I created `num_day` derived by taking the difference between `EndDate` and `BeginDate`. Additionally, I created `num_pmt` which is a ratio of `TotalCharges`/`MonthlyCharges`. `num_services`, which adds up the various services for a customer depending on whether they've answered \"Yes\" or \"No\". Date features such as `year`, `month` and `dayofweek` were extracted from `BeginDate`.\n",
    "  \n",
    "  4) To avoid data leakage, I stratfied and split the dataset into train and test into a ratio of 80:20. I create a copy of this dataset, as I wanted to test whether `num_days` caused any leakage`; I applied Oridinal Encoding for the `Type` and `PaymentMethod` features.\n",
    "  \n",
    "  4.1) I also scaled the numerical features such as `num_days`, `num_pmt`, `num_services`, `MonthlyCharges`, `TotalCharges`, including the date features.\n",
    "  \n",
    "  4.2) I One-hot encoded the boolean features.\n",
    "  \n",
    "  5) Excluding the Dummy model, I built 6 models using LogisticRegression, RandomForestClassifier and CatBoostClassifier. Each model was trained on the 2 datasets.\n",
    "  \n",
    "  5.1) I used 5-fold cross validation during GridSearch to identify useful hyperparameters for the respective models. Only 1 or 2 hyperparameters were tuned to save time.\n",
    "  \n",
    "  5.2) With leakage, the LogisticRegression model and CatBoost hit 99% AUC ROC on the test-set. Although the former completed 20x faster.\n",
    "  \n",
    "**Steps skipped**\n",
    "\n",
    "1)  Upsampling because this only slightly improved the AUC, and after a point was causing the RandomForest and CatBoost to overfit to the train set.\n",
    "\n",
    "2) `num_days`, `month` and `dayofweek` didn't have much signal strength relative to `num_pmt` and `year`.\n",
    "\n",
    "3) Imputation using LogisticRegression as this would have been overkill.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenges**\n",
    "1) The difficulties I encountered were after I removed the target leaked features such as `num_days`, `num_pmt`, `year`, `month`\n",
    "and `dayofweek` all in one go.\n",
    "\n",
    "1.1) Based on the feedback, I removed `num_pmt`, `num_days` and the Date features `year`, `month` and `dayofweek`, and retrained the model. This drastically reduced the score for LogisticRegression, which returned an AUC score 85%; the other models seem to overfit.\n",
    "  \n",
    "1.2) To address this, I added upsampling to the mix and changed the upsampling ratio, however, it only ended up overfitting the RandomForest and CatBoost models, and it helped the LogisticRegression models' AUC score to go up by 1%.\n",
    "  \n",
    "1.3) I changed the Ordinal features to use One-hot encoding, but that didn't help improve the performance.\n",
    "  \n",
    "1.4) I changed the train/test split to 90:10, and noticed a slight improvement.\n",
    "  \n",
    "1.5) I played with additional hyperparameters in RandomForest and CatBoost such as max_depth/depth, min_sample_leafs/l2_leaf_reg. min_sample_leafs helped reduce overfitting in RandomForest significantly, but l2_leaf_reg didn't help reduce overfitting. And a similar argument in CatBoost threw an error stating that the feature is not supported on CPU.\n",
    "  \n",
    "1.6) After more than an hour, I decided to reuse only `month` and `dayofweek` along with `num_pmt` and `num_days`. Surprisingly, this helped increase the AUC to 87% using LogisticRegression.\n",
    "  \n",
    "1.7) I dropped upsampling from the mix, and removed `dayofweek` to see if this would affect the score, but it didn't.\n",
    "  \n",
    "1.8) This time, I dropped `month`, `dayofweek` and `num_days`. I re-introduced `year into the mix along with `num_pmt`, and this boosted my AUC score to 91% using LogisticRegression; The RandomForestClassifier's performance also improved with slight overfitting. However, CatBoost was severly overfitting although the AUC had improved on the test set.\n",
    "  \n",
    "1.9) What worked was increasing the train-test split to 90:10, removing `num_days`, `month`, and `dayofweek`, and retaining `num_pmt` and `year` with the other one-hot encoded features. Upsampling didn't help to improve the performance beyond this point.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key steps taken**\n",
    "\n",
    "1) Feature engineering - Finding a golden feature which improves the signal to noise ratio helped me a lot. \n",
    "\n",
    "2) Playing with train-test split also helped.\n",
    "\n",
    "3) Avoiding leakage by splitting the data into train/test before scaling and applying ordinal enconding also helped.\n",
    "\n",
    "4) Hyperparameter tuning along with 5-fold cross validation made me comfortable knowing that the model would generalize\n",
    "better to new data.\n",
    "\n",
    "5) Not to forget, EDA also helped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final model**\n",
    "\n",
    "1) Because of the choice of features, I was able to build a simple model using LogisticRegression which achieved\n",
    "an AUC ROC score of 91% on the test set. This model took about 5 seconds to train, and didn't overfit either."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 124,
    "start_time": "2021-08-11T15:53:39.668Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
